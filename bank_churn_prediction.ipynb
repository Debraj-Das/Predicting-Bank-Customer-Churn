{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'https://www.kaggle.com/competitions/playground-series-s4e1/data'\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('playground-series-s4e1/test.csv')\n",
    "df = pd.read_csv('playground-series-s4e1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Surname'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEngineering(df):\n",
    "    df['Senior'] = df['Age'].apply(lambda x: 1 if x > 60 else 0).astype('category')\n",
    "    df['Active_By_CreditCard'] = df['HasCrCard'] * df['IsActiveMember']\n",
    "    df['Active_By_CreditCard'] = df['Active_By_CreditCard'].astype('category')\n",
    "    df['Products_By_Tenure']  = df['Tenure'] / df['NumOfProducts']\n",
    "    df['AgeCat'] = np.round(df['Age'] / 20).astype('int').astype('category').astype('category')\n",
    "    df['Zero_Balance'] = df['Balance'].apply(lambda x: 1 if x == 0 else 0).astype('category')\n",
    "    df['HasCrCard'] = df['HasCrCard'].astype('category')\n",
    "    df['Exited'] = df['Exited'].astype('category')\n",
    "    df['IsActiveMember'] = df['IsActiveMember'].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FeatureEngineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'CustomerId', 'Surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def FindOutliers(df, name_of_feature):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "    # Custom boxplot settings\n",
    "    boxprops1 = dict(facecolor='skyblue', color='skyblue')\n",
    "    whiskerprops1 = dict(color='skyblue')\n",
    "    capprops1 = dict(color='skyblue')\n",
    "    medianprops1 = dict(color='blue')\n",
    "    flierprops1 = dict(marker='o', color='white', markersize=5)\n",
    "\n",
    "    boxprops2 = dict(facecolor='lightgreen', color='lightgreen')\n",
    "    whiskerprops2 = dict(color='lightgreen')\n",
    "    capprops2 = dict(color='lightgreen')\n",
    "    medianprops2 = dict(color='green')\n",
    "    flierprops2 = dict(marker='o', color='white', markersize=5)\n",
    "\n",
    "    # Box plot without outliers\n",
    "    ax[0].boxplot(df[name_of_feature], vert=True, patch_artist=True, showfliers=False,\n",
    "                  boxprops=boxprops1, whiskerprops=whiskerprops1, capprops=capprops1, medianprops=medianprops1)\n",
    "    ax[0].set_title('Only Whiskers', fontsize=14, fontweight='bold')\n",
    "    ax[0].set_xlabel(name_of_feature, fontsize=12)\n",
    "\n",
    "    # Box plot with outliers\n",
    "    ax[1].boxplot(df[name_of_feature], vert=True, patch_artist=True, showfliers=True,\n",
    "                  boxprops=boxprops2, whiskerprops=whiskerprops2, capprops=capprops2, medianprops=medianprops2, flierprops=flierprops2)\n",
    "    ax[1].set_title('Whiskers and Outliers', fontsize=14, fontweight='bold')\n",
    "    ax[1].set_xlabel(name_of_feature, fontsize=12)\n",
    "\n",
    "    # Set common properties for both subplots\n",
    "    for a in ax:\n",
    "        a.yaxis.label.set_color('black')\n",
    "        a.tick_params(axis='x', colors='black')\n",
    "        a.tick_params(axis='y', colors='black')\n",
    "        a.spines['top'].set_color('black')\n",
    "        a.spines['bottom'].set_color('black')\n",
    "        a.spines['left'].set_color('black')\n",
    "        a.spines['right'].set_color('black')\n",
    "\n",
    "    # Common y-axis label\n",
    "    fig.text(0.04, 0.5, name_of_feature, va='center', ha='center', rotation='vertical', color='black', fontsize=12)\n",
    "\n",
    "    # Main title\n",
    "    fig.suptitle(f'Outliers Of {name_of_feature}', fontsize=16, color='black', fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    FindOutliers(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "for i in numeric_columns:\n",
    "    plt.hist(df[i], color='teal', edgecolor='black', linewidth=1.2)\n",
    "    plt.title(\"Distribution of \" + i)\n",
    "    plt.xlabel(\"Values of \" + i)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, color='gray')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "for i in categorical_columns:\n",
    "    plt.bar(df[i].value_counts().index, df[i].value_counts().values, color='#b5651d')\n",
    "    plt.title(\"Bar Chart of \" + i)\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, color='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Plot the heatmap with a different colormap\n",
    "plt.figure(figsize=(10, 8))  # Optional: Adjust the figure size\n",
    "sns.heatmap(df[numeric_columns].corr(), cmap='coolwarm', annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('playground-series-s4e1/test.csv')\n",
    "df = pd.read_csv('playground-series-s4e1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FeatureEngineering(df)\n",
    "df = df.drop(columns=['id', 'CustomerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_columns = categorical_columns.drop(['Exited', 'Surname'])\n",
    "surname_column = 'Surname'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "surname_transformer = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(max_features=3000)),\n",
    "    ('svd', TruncatedSVD(n_components=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(transformers=[\n",
    "    ('categorical', categorical_transformer, categorical_columns),\n",
    "    ('numerical', numerical_transformer, numeric_columns),\n",
    "    ('surname', surname_transformer, surname_column)\n",
    "], remainder = 'passthrough')\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42, stratify = df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBasedModelList(class_weights=None):\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression(max_iter=1000, class_weight=class_weights)))\n",
    "    models.append(('KNN'  , KNeighborsClassifier()))\n",
    "    models.append(('CART' , DecisionTreeClassifier(class_weight=class_weights)))\n",
    "    models.append(('AB'   , AdaBoostClassifier()))\n",
    "    models.append(('GBM'  , GradientBoostingClassifier()))\n",
    "    models.append(('RF'   , RandomForestClassifier(class_weight=class_weights)))\n",
    "    models.append(('ET'   , ExtraTreesClassifier(class_weight=class_weights)))\n",
    "    models.append(('XGB'  , XGBClassifier()))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSetPerformance(models, X_train, y_train):\n",
    "    names = []\n",
    "    roc_auc = []\n",
    "    scoring = 'roc_auc'\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models:     \n",
    "        roc_auc_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "     \n",
    "        print(f'The score of {name} (ROC AUC): {roc_auc_scores.mean():.4f}')\n",
    "        print('-------------------------------------------------------------')\n",
    "        \n",
    "        names.append('based' + str(name) + 'train')\n",
    "        roc_auc.append(roc_auc_scores)\n",
    "    \n",
    "    return names, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotResults():\n",
    "  def __Trace(self, model_name, values):\n",
    "    trace = go.Box(\n",
    "        y = values,\n",
    "        name = model_name,\n",
    "        boxpoints = False\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "  def PlotBox(self, names, results):\n",
    "    data = []\n",
    "    for i in range(len(names)):\n",
    "      data.append(self.__Trace(names[i], results[i]))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = 'Comparing Models'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreDataframe(names, roc_auc):\n",
    "    def __RoundingResults(roc_auc):\n",
    "        scores = []\n",
    "        for score in roc_auc:\n",
    "            if isinstance(score, np.ndarray):\n",
    "                scores.append(np.round(score.mean(), 4))\n",
    "            else:\n",
    "                try: \n",
    "                    scores.append(np.round(float(score), 4))\n",
    "                except ValueError:\n",
    "                    scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    scores = __RoundingResults(roc_auc)\n",
    "\n",
    "    df = pd.DataFrame({'Name': names, 'ROC_AUC': scores})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetBasedModelList(class_weights = 'balanced')\n",
    "names, roc_auc = TrainSetPerformance(models, X_train, y_train)\n",
    "PlotResults().PlotBox(names, roc_auc)\n",
    "score_based_models = ScoreDataframe(names, roc_auc)\n",
    "score_based_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetModelDict(class_weights=None):\n",
    "    models = {\n",
    "        'LR': LogisticRegression(max_iter=1000, class_weight=class_weights),\n",
    "        'KNN': KNeighborsClassifier(algorithm='brute'),\n",
    "        'CART': DecisionTreeClassifier(class_weight=class_weights),\n",
    "        'AB': AdaBoostClassifier(),\n",
    "        'GBM': GradientBoostingClassifier(),\n",
    "        'RF': RandomForestClassifier(class_weight=class_weights),\n",
    "        'ET': ExtraTreesClassifier(class_weight=class_weights),\n",
    "        'XGB': XGBClassifier()\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'LR': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    },\n",
    "    'CART': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [None, 10, 20, 30, 50],\n",
    "        'min_samples_split': [2, 10, 20],\n",
    "        'min_samples_leaf': [1, 5, 10]\n",
    "    },\n",
    "    'AB': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5, 1.0]\n",
    "    },\n",
    "    'GBM': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5]\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'ET': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'XGB': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'gamma': [0, 0.1, 0.5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetModelDict()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "roc_auc = []\n",
    "names = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        grid = RandomizedSearchCV(model, param_grids[name], cv=cv, scoring=scoring, n_jobs=-1, verbose=0, error_score=np.nan, n_iter=100, random_state=42)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_score = grid.best_score_\n",
    "        best_params = grid.best_params_\n",
    "        names.append('tuned' + str(name) + 'train')\n",
    "        roc_auc.append(best_score)\n",
    "        print(f'Best roc_auc of {name} is: {best_score:.4f}')\n",
    "        print(f'Best params of {name} are: {best_params}')\n",
    "        print('-------------------------------------------------------------------------------------------')\n",
    "    except Exception as e:\n",
    "        print(f'Error occurred for {name}: {e}')\n",
    "        names.append(name)\n",
    "        roc_auc.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "score_tuned_models = ScoreDataframe(names, roc_auc)\n",
    "score_tuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictOnTestSet(models, X_train, X_test, y_train, y_test):\n",
    "    names = []\n",
    "    roc_auc = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            pred_proba = model.decision_function(X_test)\n",
    "        \n",
    "        roc_auc_result = roc_auc_score(y_test, pred_proba)\n",
    "        roc_auc.append(roc_auc_result)\n",
    "        names.append('tuned' + str(name) + 'test')\n",
    "        \n",
    "        print(f'ROC_AUC on test set of {name} is: {roc_auc_result:.4f}')\n",
    "        print(classification_report(y_test, pred))\n",
    "        print('------------------------------------------------------------------------')\n",
    "        \n",
    "    \n",
    "    return names, roc_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTunedModelDict(class_weight=None):\n",
    "    models = {\n",
    "        'LR': LogisticRegression(max_iter=1000, C=100, penalty='l1', solver='saga', class_weight=class_weight),\n",
    "        'KNN': KNeighborsClassifier(algorithm='kd_tree', n_neighbors=9, weights='distance'),\n",
    "        'CART': DecisionTreeClassifier(splitter='random', max_depth=10, criterion='gini', \n",
    "                                       min_samples_split=2, min_samples_leaf=5, class_weight=class_weight),\n",
    "        'AB': AdaBoostClassifier(learning_rate=1.0, n_estimators=200),\n",
    "        'GBM': GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=200, \n",
    "                                          subsample=1.0, min_samples_split=10, min_samples_leaf=5),\n",
    "        'RF': RandomForestClassifier(n_estimators=100, max_depth=10, criterion='entropy', \n",
    "                                     min_samples_split=10, min_samples_leaf=5, bootstrap=False, class_weight=class_weight),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=None, \n",
    "                                   min_samples_split=2, min_samples_leaf=5, bootstrap=False, class_weight=class_weight),\n",
    "        'XGB': XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8, \n",
    "                             colsample_bytree=0.8, gamma=0.5)\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetTunedModelDict()\n",
    "names, roc_auc = PredictOnTestSet(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tuned_models_test = ScoreDataframe(names, roc_auc)\n",
    "score_tuned_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparingModels = pd.concat([\n",
    "    score_based_models,\n",
    "    score_tuned_models,\n",
    "    score_tuned_models_test\n",
    "], axis = 1)\n",
    "comparingModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetTunedModelDict()\n",
    "models = [(name, model) for name, model in models.items()]\n",
    "voting = VotingClassifier(models, voting='soft', n_jobs=-1, verbose=0)\n",
    "voting.fit(X_train, y_train)\n",
    "pred = voting.predict(X_test)\n",
    "pred_proba = voting.predict_proba(X_test)[:,1]\n",
    "roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'ROC_AUC of VotingClassifier are: {roc_auc:.4f}')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectedModelDict(class_weight=None):\n",
    "    models = {\n",
    "        'AB': AdaBoostClassifier(learning_rate=0.5, n_estimators=100),\n",
    "        'GBM': GradientBoostingClassifier(learning_rate=0.5, max_depth=3, n_estimators=100),\n",
    "        'RF': RandomForestClassifier(n_estimators=100, max_depth=20, criterion='entropy', class_weight=class_weight),\n",
    "        'XGB': XGBClassifier(learning_rate=0.5, max_depth=3, n_estimators=100)\n",
    "    }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = SelectedModelDict(class_weight = 'balanced')\n",
    "models = [(name, model) for name, model in models.items()]\n",
    "voting = VotingClassifier(models, voting='soft', n_jobs=-1, verbose=0)\n",
    "voting.fit(X_train, y_train)\n",
    "pred = voting.predict(X_test)\n",
    "pred_proba = voting.predict_proba(X_test)[:,1]\n",
    "roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'ROC_AUC of VotingClassifier are: {roc_auc:.4f}')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetTunedModelDict()\n",
    "models = [(name, model) for name, model in models.items()]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "param_grid_meta = {\n",
    "    'final_estimator__penalty': ['l2'],\n",
    "    'final_estimator__C': [0.1, 1.0, 10.0], \n",
    "}\n",
    "\n",
    "stacking = StackingClassifier(estimators=models, final_estimator=meta_model, n_jobs=-1, verbose=0, cv=3)\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "grid = RandomizedSearchCV(stacking, param_grid_meta, cv=3, scoring=scoring, n_jobs=-1, verbose=0, n_iter=100, random_state=42)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "pred_proba = grid.predict_proba(X_test)[:,1]\n",
    "pred = grid.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, pred_proba)  \n",
    "print(f'ROC_AUC of Stacking is: {roc_auc:.4f}')\n",
    "print(f'Best params of Stacking are: {grid.best_params_}')\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
